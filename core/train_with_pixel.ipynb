{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import fetch_openml\n",
    "from torch.utils import data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from MnistNet import MnistNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 6\n",
    "BATCH_SIZE = 128\n",
    "MOMENTUM = 0.9\n",
    "LR_DECAY = 0.0005\n",
    "LR_INIT = 0.01\n",
    "IMAGE_DIM = 28\n",
    "NUM_CLASSES = 10\n",
    "DEVICE_IDS = [0, 1, 2, 3]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# print the seed value\n",
    "# seed = torch.initial_seed()\n",
    "# print('Used seed : {}'.format(seed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): MnistNet(\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(2, 2))\n",
      "      (1): ReLU()\n",
      "      (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (5): ReLU()\n",
      "      (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "      (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU()\n",
      "      (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Dropout(p=0.5, inplace=False)\n",
      "      (1): Linear(in_features=256, out_features=4096, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MnistNet created\n"
     ]
    }
   ],
   "source": [
    "mnistnet = MnistNet(num_classes=NUM_CLASSES).to(device)\n",
    "mnistnet = torch.nn.parallel.DataParallel(mnistnet, device_ids=DEVICE_IDS)\n",
    "print(mnistnet)\n",
    "print('MnistNet created')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "y = y.astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X = X.reshape(X.shape[0], 1, 28, 28)\n",
    "print(X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def attack_image(xs, img):\n",
    "    img = img.reshape(28, 28)\n",
    "    imgs = []\n",
    "    for i, x in enumerate(xs):\n",
    "            y_pos, x_pos, intensity = x\n",
    "            imgs.append(img.copy())\n",
    "            imgs[i][y_pos][x_pos] = intensity\n",
    "\n",
    "    return imgs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70000it [00:22, 3061.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X_attacked = []\n",
    "y_attacked = []\n",
    "for k, img in tqdm(enumerate(X)):\n",
    "    img = img.reshape(28, 28)\n",
    "    vec = []\n",
    "    for i in range(5, 23, 4):\n",
    "        for j in range(5, 23, 4):\n",
    "            value = 255 if img[i][j] < 128 else 0\n",
    "            pix = [i, j, value]\n",
    "            vec.append(pix)\n",
    "\n",
    "    attacked_imgs = attack_image(vec, img)\n",
    "    X_attacked+=attacked_imgs\n",
    "    y_attacked += [y[k]]*len(attacked_imgs)\n",
    "\n",
    "X_attacked = np.array(X_attacked)\n",
    "y_attacked = np.array(y_attacked)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750000 1750000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_attacked), len(y_attacked))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "X_attacked = X_attacked.reshape(X_attacked.shape[0], 1, 28, 28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "TRAIN_NUMBER = int(len(X_attacked) * TRAIN_PERCENTAGE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_attacked[:TRAIN_NUMBER], X_attacked[TRAIN_NUMBER:], y_attacked[:TRAIN_NUMBER], y_attacked[TRAIN_NUMBER:]\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float(),\n",
    "                              torch.from_numpy(y_train).long())\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True,\n",
    "                          num_workers=8,\n",
    "                          drop_last=True,\n",
    "                          batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test).float(),\n",
    "                             torch.from_numpy(y_test).long())\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True,\n",
    "                          num_workers=8,\n",
    "                          drop_last=True,\n",
    "                          batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def evaluate_model(nn_model):\n",
    "    nn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct_out = 0\n",
    "        total_out = 0\n",
    "        for pics, lbls in test_loader:\n",
    "            out = nn_model(pics)\n",
    "            pred = torch.argmax(out, dim=1)\n",
    "            total_out += lbls.shape[0]\n",
    "            correct_out += (pred == lbls).sum().item()\n",
    "\n",
    "    loss_current = criterion(out, lbls)\n",
    "    return correct_out / total_out, loss_current"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer created\n"
     ]
    }
   ],
   "source": [
    "# create optimizer\n",
    "# the one that WORKS\n",
    "optimizer = optim.Adam(params=mnistnet.parameters(), lr=0.0001)\n",
    "### BELOW is the setting proposed by the original paper - which doesn't train....\n",
    "# optimizer = optim.SGD(\n",
    "#     params=alexnet.parameters(),\n",
    "#     lr=LR_INIT,\n",
    "#     momentum=MOMENTUM,\n",
    "#     weight_decay=LR_DECAY)\n",
    "print('Optimizer created')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Scheduler created\n",
      "Starting training...\n",
      "Epoch: 1 \tStep: 200 \tLoss: 0.2748 \tAcc: 0.921875\n",
      "Epoch: 1 \tStep: 400 \tLoss: 0.1676 \tAcc: 0.9609375\n",
      "**********\n",
      "Epoch: 1 \tStep: 600 \tLoss: 0.1376 \tAcc: 0.9609375\n",
      "Epoch: 1 \tStep: 800 \tLoss: 0.1124 \tAcc: 0.9453125\n",
      "**********\n",
      "Epoch: 1 \tStep: 1000 \tLoss: 0.1092 \tAcc: 0.953125\n",
      "Epoch: 1 \tStep: 1200 \tLoss: 0.0669 \tAcc: 0.984375\n",
      "**********\n",
      "Epoch: 1 \tStep: 1400 \tLoss: 0.0954 \tAcc: 0.9609375\n",
      "Epoch: 1 \tStep: 1600 \tLoss: 0.0131 \tAcc: 1.0\n",
      "**********\n",
      "Epoch: 1 \tStep: 1800 \tLoss: 0.0263 \tAcc: 0.9921875\n",
      "Epoch: 1 \tStep: 2000 \tLoss: 0.0861 \tAcc: 0.9609375\n",
      "**********\n",
      "Epoch: 1 \tStep: 2200 \tLoss: 0.0576 \tAcc: 0.9765625\n",
      "Epoch: 1 \tStep: 2400 \tLoss: 0.0405 \tAcc: 0.9921875\n",
      "**********\n",
      "Epoch: 1 \tStep: 2600 \tLoss: 0.0111 \tAcc: 0.9921875\n",
      "Epoch: 1 \tStep: 2800 \tLoss: 0.0839 \tAcc: 0.9921875\n",
      "**********\n",
      "Epoch: 1 \tStep: 3000 \tLoss: 0.0042 \tAcc: 1.0\n",
      "Epoch: 1 \tStep: 3200 \tLoss: 0.0046 \tAcc: 1.0\n",
      "**********\n",
      "Epoch: 1 \tStep: 3400 \tLoss: 0.0211 \tAcc: 0.9921875\n",
      "Epoch: 1 \tStep: 3600 \tLoss: 0.0115 \tAcc: 0.9921875\n",
      "**********\n",
      "Epoch: 1 \tStep: 3800 \tLoss: 0.0193 \tAcc: 0.9921875\n",
      "Epoch: 1 \tStep: 4000 \tLoss: 0.0047 \tAcc: 1.0\n",
      "**********\n",
      "Epoch: 1 \tStep: 4200 \tLoss: 0.0223 \tAcc: 0.9921875\n",
      "Epoch: 1 \tStep: 4400 \tLoss: 0.0059 \tAcc: 1.0\n",
      "**********\n",
      "Epoch: 1 \tStep: 4600 \tLoss: 0.0063 \tAcc: 1.0\n",
      "Epoch: 1 \tStep: 4800 \tLoss: 0.0117 \tAcc: 0.9921875\n",
      "**********\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 27\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# update the parameters\u001B[39;00m\n\u001B[1;32m     26\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 27\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# log the information and add to tensorboard\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/mnist_nn/lib/python3.10/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/mnist_nn/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# multiply LR by 1 / 10 after every 30 epochs\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "print('LR Scheduler created')\n",
    "\n",
    "accuracy_test_stat = []\n",
    "accuracy_train_stat = []\n",
    "loss_test_stat = []\n",
    "loss_train_stat = []\n",
    "\n",
    "# start training!!\n",
    "print('Starting training...')\n",
    "total_steps = 1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_tr_accuracy = 0\n",
    "    epoch_tr_loss = 0\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    for imgs, classes in train_loader:\n",
    "        imgs, classes = imgs.to(device), classes.to(device)\n",
    "\n",
    "        # calculate the loss\n",
    "        output = mnistnet(imgs)\n",
    "        loss = F.cross_entropy(output, classes)\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # log the information and add to tensorboard\n",
    "        if total_steps % 200 == 0:\n",
    "            with torch.no_grad():\n",
    "                predictions = torch.argmax(output, dim=1)\n",
    "                accuracy = (predictions == classes).sum() / len(predictions)\n",
    "\n",
    "                epoch_tr_accuracy = accuracy.item()\n",
    "                epoch_tr_loss = loss.item()\n",
    "\n",
    "                print('Epoch: {} \\tStep: {} \\tLoss: {:.4f} \\tAcc: {}'\n",
    "                      .format(epoch + 1, total_steps, loss.item(), epoch_tr_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "        # print out gradient values and parameter average values\n",
    "        if total_steps % 400 == 0:\n",
    "            with torch.no_grad():\n",
    "                # print and save the grad of the parameters\n",
    "                # also print and save parameter values\n",
    "                print('*' * 10)\n",
    "                for name, parameter in mnistnet.named_parameters():\n",
    "                    if parameter.grad is not None:\n",
    "                        avg_grad = torch.mean(parameter.grad)\n",
    "\n",
    "                        # print('\\t{} - grad_avg: {}'.format(name, avg_grad))\n",
    "                        # tbwriter.add_scalar('grad_avg/{}'.format(name), avg_grad.item(), total_steps)\n",
    "                        # tbwriter.add_histogram('grad/{}'.format(name),\n",
    "                        #                       parameter.grad.cpu().numpy(), total_steps)\n",
    "                    if parameter.data is not None:\n",
    "                        avg_weight = torch.mean(parameter.data)\n",
    "\n",
    "                        # print('\\t{} - param_avg: {}'.format(name, avg_weight))\n",
    "                        # tbwriter.add_histogram('weight/{}'.format(name),\n",
    "                        #                       parameter.data.cpu().numpy(), total_steps)\n",
    "                        # tbwriter.add_scalar('weight_avg/{}'.format(name), avg_weight.item(), total_steps)\n",
    "        total_steps += 1\n",
    "\n",
    "    # epoch_tr_accuracy /= len(train_loader)\n",
    "    # epoch_tr_loss /= len(train_loader)\n",
    "\n",
    "    a, l = evaluate_model(mnistnet)\n",
    "    accuracy_train_stat.append(epoch_tr_accuracy)\n",
    "    accuracy_test_stat.append(a)\n",
    "\n",
    "    loss_train_stat.append(epoch_tr_loss)\n",
    "    loss_test_stat.append(l)\n",
    "\n",
    "    # print(accuracy_test_stat, accuracy_train_stat, loss_test_stat, loss_train_stat)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = range(1, NUM_EPOCHS+1)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(epochs, loss_train_stat)\n",
    "plt.plot(epochs, loss_test_stat)\n",
    "plt.legend([\"Train Loss\", \"Test Loss\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "plt.figure(figsize=(10, 7))\n",
    "print(accuracy_train_stat)\n",
    "plt.plot(epochs, accuracy_train_stat)\n",
    "plt.plot(epochs, accuracy_test_stat)\n",
    "plt.legend([\"Train Accuracy\", \"Test Accuracy\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "classes = [2, 3, 6, 8, 9, 1, 0, 4, 7, 5]\n",
    "for i in range(10):\n",
    "    img = cv2.imread(\"../my_dataset/\"+str(i+1)+\".png\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sharp_filter = np.array([[-1, 0, -1],\n",
    "                             [ 0, 7,  0],\n",
    "                             [-1, 0, -1]])\n",
    "    img = cv2.filter2D(img, ddepth=-1, kernel=sharp_filter)\n",
    "\n",
    "    img = cv2.bitwise_not(img)\n",
    "    img = img.astype('float32')\n",
    "    data.append(img)\n",
    "\n",
    "data = np.reshape(data,(len(data), 1, 28, 28))\n",
    "# data = np.array(data)\n",
    "classes = np.array(classes)\n",
    "\n",
    "print(data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(data[i].reshape(28, 28), cmap='Greys')\n",
    "    plt.title(\"Цифра %d\" % classes[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_dataset = TensorDataset(torch.from_numpy(data).float(),\n",
    "                                   torch.from_numpy(classes).long())\n",
    "experiment_loader = DataLoader(experiment_dataset,\n",
    "                          shuffle=False,\n",
    "                          # pin_memory=True,\n",
    "                          # num_workers=8,\n",
    "                          # drop_last=True,\n",
    "\n",
    "                          batch_size=BATCH_SIZE)\n",
    "\n",
    "mnistnet.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in experiment_loader:\n",
    "        outputs = mnistnet(images)\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"Test accurac\"\n",
    "          \"y:\",\n",
    "        100 * correct / total, \"%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(data[i].reshape(28, 28), cmap='Greys')\n",
    "    plt.title(\"%d, pred: %d\" % (classes[i], predicted[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(mnistnet, 'mnistnet_pixel.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mdl = torch.load('mnistnet_pixel.pkl')\n",
    "mdl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for images, labels in test_loader:\n",
    "        outputs = mdl(images)\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        print((predicted == labels).sum().item() / len(labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}